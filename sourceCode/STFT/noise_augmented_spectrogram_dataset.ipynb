{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom scipy import signal\nfrom scipy.io import wavfile\nimport matplotlib.pyplot as plt\nimport soundfile as sf\nimport librosa\nimport keras\nfrom keras.models import Sequential\nfrom keras.datasets import mnist\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.initializers import Constant\nfrom keras import backend as K\nfrom keras.layers import PReLU","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Audio augmentation library**"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install nlpaug\n\nimport nlpaug.augmenter.audio as naa\nnaug = naa.NoiseAug()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Extract data from the dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"inputData = np.empty((6898,50000))\ntargetData = np.empty(6898)\nroot = '../input/respiratory-sound-database/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/'\nfilenames = [s.split('.')[0] for s in os.listdir(path = root) if '.txt' in s]\ni_list = []\nrec_annotations = []\nrec_annotations_dict = {}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Sample rate is 10kHz and max. length of a sample is 5s. Functions to zero pad if available audio is less than 5s and prepare the target data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def Extract_Annotation_Data(file_name, root):\n    tokens = file_name.split('_')\n    recording_info = pd.DataFrame(data = [tokens], columns = ['Patient number', 'Recording index', 'Chest location','Acquisition mode','Recording equipment'])\n    recording_annotations = pd.read_csv(os.path.join(root, file_name + '.txt'), names = ['Start', 'End', 'Crackles', 'Wheezes'], delimiter= '\\t')\n    return (recording_info, recording_annotations)\n\ndef slice_data(start, end, raw_data,  sample_rate):\n    max_ind = len(raw_data)\n    new_sample_rate = 10000\n    new_raw_data = signal.resample(raw_data,int(max_ind*new_sample_rate/sample_rate))\n    new_max_ind = len(new_raw_data)\n    start_ind = min(int(start * new_sample_rate), new_max_ind)\n    end_ind = min(int(end * new_sample_rate), new_max_ind)\n    max_len = 50000\n    \n    if (end_ind-start_ind)>max_len:\n        return new_raw_data[start_ind:(start_ind+max_len)]\n    \n    elif ((end_ind-start_ind)<max_len):\n        return np.concatenate((new_raw_data[start_ind:end_ind],np.zeros(max_len+start_ind-end_ind)))\n    \n    elif (end_ind-start_ind)==max_len:\n        return new_raw_data[start_ind:end_ind]\n    \ndef getClass(df,index):\n    if(df.at[index,'Wheezes']==0 and df.at[index,'Crackles']==0):\n        return 0\n    elif(df.at[index,'Wheezes']==1 and df.at[index,'Crackles']==0):\n        return 1\n    elif(df.at[index,'Wheezes']==0 and df.at[index,'Crackles']==1):\n        return 2\n    elif(df.at[index,'Wheezes']==1 and df.at[index,'Crackles']==1):\n        return 3","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Display sample annotation table**"},{"metadata":{"trusted":true},"cell_type":"code","source":"for s in filenames:\n    (i,a) = Extract_Annotation_Data(s, root)\n    i_list.append(i)\n    rec_annotations.append(a)\n    rec_annotations_dict[s] = a\nrecording_info = pd.concat(i_list, axis = 0)\nrecording_info.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Extract audio files and zero pad it if required and create target data for training**"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"l=0\nfor i in rec_annotations_dict:\n    j = rec_annotations_dict[i]\n    for k in range(j.shape[0]):\n        data,sampleRate = sf.read(root+i+'.wav')\n        inputData[l] = slice_data(j.at[k,'Start'],j.at[k,'End'], data, sampleRate)\n        targetData[l] = getClass(j,k)\n        l=l+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(targetData.shape)\nprint(inputData.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Noise augmentation of audio sample**"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"inputDataNoise = np.zeros((6898, 50000))\n\nfor i in range(inputDataNoise.shape[0]): \n    inputDataNoise[i, :] = naug.augment(inputData[i, :])\n    print(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputDataNoise.shape\ninputData = np.copy(inputDataNoise)\ndel inputDataNoise","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sampleRate = 10000","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Display sample audio time-domain waveform, spectrum and spectrogram**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nsampleNo = 4345\nsample = inputData[sampleNo,:]\nt = np.linspace(0, sample.size/sampleRate, sample.size)\n\nplt.figure(figsize = (20,5))\nplt.plot(t, sample)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy as sc\n\nz = sc.fft.fft(sample)\nz = np.abs(z[0:int(500*z.size/sampleRate)])\nz = np.concatenate((z[::-1], z))\nf = np.linspace(-500, 500, z.size)\n\nplt.figure(figsize = (20,5))\nplt.plot(f, z*2/sample.size)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import librosa\n\nstft = np.abs(librosa.stft(sample, n_fft = 1024, hop_length = 512, win_length = 1024))\nstft = 20*np.log(np.abs(stft) + 1e-10)\n\ncutoff_freq = 3000\n\nstft_low_freq = stft[0:int(cutoff_freq*2*stft.shape[0]/sampleRate), :]\ntf = np.linspace(0, sample.size/sampleRate, stft.shape[1])\nff = np.linspace(0, cutoff_freq, stft_low_freq.shape[0])\n\nplt.figure(figsize = (20, 5))\nplt.pcolormesh(tf, ff, stft_low_freq, vmin = stft.min(), vmax = stft.max(), shading='gouraud')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(stft_low_freq.shape)\nprint(stft.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Convert the audio data to spectrogram data and chop off the spectrogram to 3 kHz**"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"stft_dataset = []\ncutoff_freq = 3000\n\nfor i in range(inputData.shape[0]):\n    sample_audio = inputData[i,:]\n    stft = np.abs(librosa.stft(sample_audio, n_fft = 1024, hop_length = 512, win_length = 1024))\n    stft = 20*np.log(np.abs(stft) + 1e-10)\n    stft = stft[0:int(cutoff_freq*2*stft.shape[0]/sampleRate), :]\n    print(i)\n    stft_dataset.append(stft)\n\nstft_dataset = np.array(stft_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stft_dataset.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Resize the spectrogram to reduce the data consumption and to make it feasible for training**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\n\ndim = (125, 40)\nstft_resized = []\nfor i in range(stft_dataset.shape[0]):\n    sample = cv2.resize(stft_dataset[i], dim, interpolation = cv2.INTER_AREA)\n    stft_resized.append(sample)\n\nstft_resized = np.array(stft_resized)\nstft_resized.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Display a resized spectrogram**"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_resized = stft_resized[sampleNo, :]\n\ntf = np.linspace(0, 5, sample_resized.shape[1])\nff = np.linspace(0, cutoff_freq, sample_resized.shape[0])\n\nplt.figure(figsize = (20, 5))\nplt.pcolormesh(tf, ff, sample_resized, vmin = stft_resized.min(), vmax = stft_resized.max(), shading='gouraud')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Save the spectrogram dataset and target data to kaggle output**"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.save('/kaggle/working/stft_dataset.npy', stft_resized)\nnp.save('/kaggle/working/target.npy', targetData)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}