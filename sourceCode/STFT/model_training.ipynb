{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom scipy import signal\nimport soundfile as sf\nimport keras\nfrom keras.models import Sequential\nfrom keras.datasets import mnist\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization\nfrom keras.layers import Conv2D, MaxPooling2D, Input\nfrom keras.initializers import Constant\nfrom keras.regularizers import l2\nfrom keras.applications import ResNet101\nfrom keras import backend as K\nfrom keras.layers import PReLU\nimport cv2\nimport librosa","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Load the augmented audio data and target labels**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"X_train_1 = np.load('../input/spec-dataset-3/stft_dataset.npy')\nY_train_1 = np.load('../input/spec-dataset-3/target.npy')\nX_train_2 = np.load('../input/spec-dataset-laug/stft_dataset.npy')\nY_train_2 = np.load('../input/spec-dataset-laug/target.npy')\nX_train_3 = np.load('../input/spec-dataset-naug/stft_dataset.npy')\nY_train_3 = np.load('../input/spec-dataset-naug/target.npy')\nX_train_4 = np.load('../input/spec-dataset-paug/stft_dataset.npy')\nY_train_4 = np.load('../input/spec-dataset-paug/target.npy')\n\nX_train = np.concatenate((X_train_1, X_train_2, X_train_3, X_train_4))\nY_train = np.concatenate((Y_train_1, Y_train_2, Y_train_3, Y_train_4))\nprint(X_train.shape)\nprint(Y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Shuffle the data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"indices = np.arange(X_train.shape[0])\nnp.random.shuffle(indices)\n\nX_train = X_train[indices]\nY_train = Y_train[indices]\nprint(X_train.shape)\nprint(Y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Distribution of data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"unique, counts = np.unique(Y_train, return_counts = True)\nprint(unique)\nprint(counts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"no_classes = 4","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**One hot encoding**"},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train = keras.utils.to_categorical(Y_train, num_classes = no_classes)\nprint(Y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Normalize the data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = librosa.util.normalize(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\ninput_shape = X_train.shape[-3:]\ninput_shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Train-test split**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_train, Y_train, test_size=0.05, random_state=42, stratify = Y_train)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Train-val split**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42, stratify = y_train)\nprint(X_train.shape)\nprint(X_val.shape)\nprint(y_train.shape)\nprint(y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32, kernel_size = (3, 3), activation = 'relu', input_shape = input_shape, kernel_regularizer = l2(0.01)))\nmodel.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu', kernel_regularizer = l2(0.01)))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(0.3))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu', kernel_regularizer = l2(0.01)))\nmodel.add(Conv2D(128, kernel_size = (3, 3), activation = 'relu', kernel_regularizer = l2(0.01)))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(0.3))\nmodel.add(BatchNormalization())\n\nmodel.add(Flatten())\n\nmodel.add(Dense(64, activation = 'relu')) \nmodel.add(Dense(32, activation = 'relu')) \nmodel.add(Dropout(0.3)) \nmodel.add(Dense(no_classes, activation = 'softmax'))\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Hyperparameters**"},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 256\nno_epochs = 600\nverbosity = 1\nlr = 0.001","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Save the best model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import h5py\n\nfilepath=\"/kaggle/working/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\ncallback = [checkpoint]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Compile and train the model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss = keras.losses.categorical_crossentropy, optimizer = keras.optimizers.Adam(learning_rate = lr), metrics = ['accuracy'])\nhistory = model.fit(X_train, y_train, batch_size = batch_size, epochs = no_epochs, verbose = verbosity, validation_data = (X_val, y_val), callbacks = [callback])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot the loss and accuracies**"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='Training accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation accuracy')\nplt.title('training / validation accuracies')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(loc=\"upper left\")\nplt.show()\nplt.plot(history.history['loss'], label='Training loss')\nplt.plot(history.history['val_loss'], label='Validation loss')\nplt.title('training / validation loss values')\nplt.ylabel('Loss value')\nplt.xlabel('Epoch')\nplt.legend(loc=\"upper left\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Evaluate model performance on test set**"},{"metadata":{"trusted":true},"cell_type":"code","source":"best_model = tf.keras.models.load_model('./weights-improvement-228-0.91.hdf5') # replace with path of best model\nprediction = best_model.predict(X_test)\n\npr = np.argmax(prediction, axis = 1)\ngt = np.argmax(y_test, axis = 1)\n\npercentage = np.sum((pr == gt).astype(int)) * 100 / pred.shape[0]\npercentage","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Plot the confusion matrix**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\ncm =confusion_matrix(gt, pr)  \nindex = ['both wheeze and crackle absent','wheeze present crackle absent','crackle present wheeze absent', 'both wheeze and crackle present']  \ncolumns = ['both wheeze and crackle absent','wheeze present crackle absent','crackle present wheeze absent', 'both wheeze and crackle present'] \ncm_df = pd.DataFrame(cm,columns,index)\n\nfor i in range(4):\n    cm_df.iloc[i] = cm_df.iloc[i] / cm_df.iloc[i].sum()\n\nplt.figure(figsize=(10,6))  \nsns.heatmap(cm_df, annot=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}